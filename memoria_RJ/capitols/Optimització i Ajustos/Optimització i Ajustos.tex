\chapter{Optimització i Ajustos}\label{a:optimitzacioAjustos}

\section{Mètodes d'Optimització en intel·ligència artificial:\\Fonaments i Aplicacions}

\subsection*{Introducció}

La intel·ligència artificial integra múltiples estratègies d'optimització, cadascuna adaptada als diferents models d'IA. A continuació, s'exploren els mètodes més destacats, amb una anàlisi dels mecanismes i les referències acadèmiques que hem utilitzat.

\begin{enumerate}

 \item \textbf{Retropropagació en Aprenentatge Profund: } La retropropagació (\textit{backpropagation}) és com el punt i coma en el text per les xarxes neuronals artificials. Aquest algorisme es basa en un procés iteratiu en dues fases:

    \begin{enumerate}

       \item \textbf{Fase de propagació endavant}: Les dades d'entrada es transmeten a través de les capes de la xarxa, generant una predicció. Durant aquest procés, cada neurona aplica una transformació lineal seguida d'una funció d'activació no lineal, com la \textit{funció unitat rectificada uniforme} o la \textit{funció sigmoide}.

%%%%%%Aquí a lo mejor hay un error de hyperlink, hay q verlo.

     \item \textbf{Fase de propagació enrere}: Es calcula l'error entre la predicció i el valor real utilitzant una funció de pèrdua (\textit{loss function}), com l'error quadràtic mitjà (\textit{Mean Squared Error}) per a problemes de regressió o l'entropia creuada (\textit{Cross-Entropy Loss}) per a classificació. Mitjançant la regla de la cadena (\textit{chain rule}), es determina la contribució de cada paràmetre a l'error global, obtenint els gradients $\partial L/\partial W$, on $L$ representa la pèrdua i $W$ els pesos de la xarxa.

%%%%%%No entiendo que explica el JiaJun

     \item \textbf{Actualització de paràmetres}: Els pesos s'ajusten en la direcció oposada al gradient utilitzant variables del descens de gradient que s'actualitzen amb un subconjunt aleatori de dades, o optimitzadors més sofisticats com Adam (\textit{Adaptive Moment Estimation}), que adapta la taxa d'aprenentatge per a cada paràmetre.

    \end{enumerate}

% Podeu trobar més informació a~\ref{subsec:propagació} on s'explica la retropropagació de la xarxa neuronal.


 \item \textbf{Optimització en Models Generatius: } Els models generatius, com les xarxes generatives adversàries (GANs) i els autocidificadors variacionals (VAEs), empren tècniques d'optimització especialitzades.

 \textbf{Exemples:}

     \begin{enumerate}

      \item \textbf{Xarxes Generatives Adversàries (GANs):} Les GANs implica la competició entre dos models:

          \begin{enumerate}

           \item \textbf{Generador (\textit{Generator})}: Transforma un vector de soroll/aleatori(\textit{noise vector}) en dades sintètiques, intentant enganyar el discriminador.

           \item \textbf{Discriminador (\textit{Discriminator})}: Distingeix entre dades reals i generades, actuant com un classificador binari.

          \end{enumerate}

           L'entrenament es formula com un joc minimax, on la funció objectiva és:

           $$ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{\text{data}}}[\log D(x)] + \mathbb{E}_{z \sim p_z}[\log(1 - D(G(z)))] $$

           La retropropagació s'aplica alternativament amb dues xarxes, ajustant els seus paràmetres per millorar les seves funcions respectives.

           \item \textbf{Autoencoders Variacionals (VAEs):} Els VAEs optimitzen l'\textit{Evidence Lower Bound} (ELBO), que combina dos termes:

               \begin{enumerate}

                \item \textbf{Terme de reconstrucció}: Minimitza l'error entre les dades originals i les reconstruïdes.

                \item \textbf{Terme de regularització}: Minimitza la divergència de Kullback-Leibler (\textit{KL divergence}) entre la distribució latent i una distribució prior (normalment una normal estàndard).

               \end{enumerate}

            L'optimització es realitza mitjançant \textit{gradient descent} sobre l'ELBO, amb l'ajut del \textit{reparameterization trick} per a un càlcul eficient dels gradients.

            \item \textbf{Aprenentatge per Reforç i Optimització basada en Polítiques:} En l'aprenentatge per reforç (\textit{Reinforcement Learning, RL}), l'optimització se centra en maximizar la recompensa acumulada. Un enfocament prominent és el \textit{Policy Gradient}, que ajusta directament la política (\textit{policy}) mitjançant:

           $$ \nabla_\theta J(\theta) = \mathbb{E}_{\tau \sim \pi_\theta} \left[ \sum_{t=0}^T \nabla_\theta \log \pi_\theta(a_t|s_t) \cdot R(\tau) \right] $$

           on $\tau$ representa una trajectòria i $R(\tau)$ la recompensa acumulada.\\

           \textbf{Alternatives a la Retropropagació: Algorismes Evolutius:} Per a problemes on el càlcul de gradients no és factible, els algorismes genètics (\textit{Genetic Algorithms, GA}) ofereixen una solució viable. Aquests algorismes emulen l'evolució natural mitjançant:

               \begin{enumerate}

                \item \textbf{Selecció}: Els individus més aptes (\textit{fitness}) tenen major probabilitat de reproduir-se.

                \item \textbf{Encreuament (\textit{Crossover})}: Combina característiques de dos individus per generar descendència.

                \item \textbf{Mutació}: Introdueix variabilitat genètica aleatòria.

               \end{enumerate}

    \end{enumerate}


\end{enumerate}

Fonts: \cite{Rumelhart1986}, \cite{NIPS2014_f033ed80}, \cite{kingma2022autoencodingvariationalbayes}, \cite{NIPS1999_464d828b} i \cite{Holland:1975}

\section{Algoritme Gradient Descendent}\label{Algoritme_gradient}
   L'algoritme de Gradient Descendent és un algoritme imprescindible en l'entrenament de les xarxes neuronals, i de la intel·ligència artificial. Primer de tot hem d'entendre que és un gradient i una funció d'error.

    \begin{itemize}

     \item \textbf{Gradient: } En les xarxes neuronals, un gradient és un vector que indica la direcció en la qual es mou i amb quina intensitat perquè la funció d'error canviï més de pressa respecte als pesos de la xarxa neuronal. Per calcular el gradient, s'utilitza la derivada parcial de la funció de pèrdua respecte als pesos.

     \item \textbf{Funció d'error: } La funció d'error determina la diferència entre el valor estimat i el valor real, amb la finalitat d'optimitzar els paràmetres de la xarxa neuronal.

    \end{itemize}

%         \textbf{Gradient: } En les xarxes neuronals, un gradient és un vector que indica la direcció en la que es mou i amb quina intensitat per que la funció d'error cambii més ràpid respecte als pesos de la xarxa neuronal. Per calcular el gradient, s'utilitza la derivada parcial de la funció de pèrdua respecte als pesos.
%
%         \textbf{Funció d'error: } La funció d'error determina la diferència entre el valor estimat i el valor real, amb la finalitat d'optimitzar els paràmetres de la xarxa neuronal.

         L'objectiu de l'algoritme gradient descendent és minimitzar la funció d'error.
%          , és a dir, trobar la funció de pèrdua mínima. Per tal d'aconseguir-ho, s'ha de trobar el valor mínim d'aquesta funció.
%          La funció de pèrdua mínima significa que els errors dels paràmetres (pesos i biaixos) de la xarxa han de ser molt aproximades al valor real, on s'ajusten aquest paràmetres ja que no són exactes.





          A la figura~\ref{GraficaDescendet} podem apreciar quatre iteracions, el valor inicial és un punt qualsevol de la funció. En el punt 0 els paràmetres de la funció s'assignen aleatòriament, per tant, els errors poden ser grans. A cada iteració trobarem la derivada parcial, i el gradient serà l'encarregat de guiar els canvis als paràmetres.

        \begin{figure}[H]
         \centering
         \includegraphics[width=0.4\textwidth]{./figures/gradient_descendent.png}
        \caption{Gràfica de gradient descendent.~\cite{Img_gradient}}
        \label{GraficaDescendet}
         \end{figure}


          A l'inici del procés el gradient acostuma a ser molt pronunciat, però a mesura que es van generant nous paràmetres durant l'entrenament, s'anirà reduint fins al vèrtex d'aquesta corba, on els errors són mínims, aquest rep el nom de punt de convergència. En aquest punt direm que la xarxa ha après i ha ajustat millor els pesos i els biaixos.

          La fòrmula del gradient ascendent és la seguent: $\Delta w_{ij} = a \left( \frac{\partial E}{\partial w_{ij}} \right)$\\


          Aquesta és la fórmula més ràpida per arribar al punt màxim dels gradients. Per tant, la fórmula del gradient descendent seria aquesta mateixa en negatiu, perquè és la forma més ràpida de trobar el punt mínim.

          $$\Delta w_{ij} = -a \left( \frac{\partial E}{\partial w_{ij}} \right)$$

          \textbf{Explicació de la fòrmula:}\\

           $\Delta w_{ij}$: Representa quan s'ajusta el pes en una iteració de l'entrenament.

           $a$: És la constant d'aprenentatge, aquesta constant defineix quan afecta el gradient en l'actualització dels nostres paràmetres en cada iteració. Si aquest valor és gran, cada iteració és molt gran, i el punt serà incapaç d'introduir-se al punt de convergència, causant que el procés d'optimització acabi en un bucle infinit. Tanmateix, si és petit, el punt s'aproxima a poc a poc al punt de convergència, però calcularà moltes iteracions i això pot ser ineficient.

           $\left( \frac{\partial E}{\partial w_{ij}} \right)$: És la derivada parcial de $E$ respecte a $\Delta w_{ij}$. \\

           La figura~\ref{Gran i petit} és una representació 2D del gradient descendent, però en situacions reals el gradient descendent acostuma a representar-se en 3D tal com mostra la figura~\ref{f:gradient3D}.

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{./figures/constant_gradient.png}
        \caption{Gràfiques de valors gran i petit de la constant d'aprenentatge.~\cite{Img_granpetit}}
        \label{Gran i petit}
    \end{figure}

    \begin{figure}[H]
    \centering
    \includegraphics[width=0.7\textwidth]{./figures/gradient_descendent3d.png}
    \caption{Repressentació del gradient descendent en 3D.~\cite{Img_3d}}
    \label{f:gradient3D}
    \end{figure}


\bigskip

Fonts:~\cite{IBM_Gradient} i~\cite{Video_Gradient}.

%  \textbf{Funció de pèrdua (o error)}\label{subsec:pèrdua}
%      Un sistema per avaluar l'encert de les prediccions, comparant-les amb resultats reals (quan es disposa d'ells). Si la predicció és incorrecta, aquesta funció quantifica la magnitud de l'error.
% \subsection{La regla de la cadena}\label{subsec:cadena}
%
% En l'aprenentatge automàtic, sovint es treballa amb funcions compostes complexes que depenen de diversos paràmetres i capes. Per tal de facilitar el càlcul dels gradients i optimitzar el rendiment computacional, s'utilitza la \textbf{regla de la cadena}.
%
% La regla de la cadena és una tècnica de derivació que ens permet derivar la composició de funcions de manera senzilla. D’aquesta manera, es poden calcular les derivades de manera escalonada i eficient, especialment en el context de l’algoritme de propagació enrere (backpropagation).
%
% Per exemple, si tenim una funció composta de la forma:
% $$ L = f(g(h(x)))$$
% La derivada de \( L \) respecte a \( x \) s'obté aplicant la regla de la cadena:
% $$L'(x) = f'(g(h(x))) \cdot g'(h(x)) \cdot h'(x)$$
% Aquest procediment és fonamental per entrenar xarxes neuronals, ja que permet calcular com cada pes de la xarxa contribueix a l'error global, i així ajustar-los mitjançant tècniques com el descens de gradient.

%fonts:\href{https://medium.com/%40ppuneeth73/the-chain-rule-of-calculus-the-backbone-of-deep-learning-backpropagation-9d35affc05e7}{Medium deep machine-learning} \ \href{https://www.geeksforgeeks.org/machine-learning/chain-rule-derivative-in-machine-learning/}{Greek machine-learning} Aquesta pàgina ja no existeix.
